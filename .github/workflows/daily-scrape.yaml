name: Scrape and Update Data

on:
  workflow_dispatch:  # Allows manual trigger from GitHub UI
  schedule:
    - cron: '0 0 * * *'  # Scheduled to run at midnight UTC every day

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest  # Specifies the runner environment

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2  # Checks out your repository under $GITHUB_WORKSPACE

    - name: Set up Python 3.x
      uses: actions/setup-python@v2  # Sets up Python environment
      with:
        python-version: '3.x'  # Replace '3.x' with a specific version if needed

    - name: Install dependencies
      run: |
        pip install requests beautifulsoup4 splinter webdriver_manager
        # Add any other dependencies your script requires

    - name: Install Chrome
      run: |
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable

    - name: Install ChromeDriver
      run: |
        CHROMEDRIVER_VERSION=`curl -sS chromedriver.storage.googleapis.com/LATEST_RELEASE`
        wget -N https://chromedriver.storage.googleapis.com/$CHROMEDRIVER_VERSION/chromedriver_linux64.zip -P ~/
        unzip ~/chromedriver_linux64.zip -d ~/
        sudo mv -f ~/chromedriver /usr/local/bin/chromedriver
        sudo chmod 0755 /usr/local/bin/chromedriver

    - name: Run scrape.py
      run: python scrape.py  # Executes your script

    # (Optional) Add steps for committing and pushing changes to the repository if needed
